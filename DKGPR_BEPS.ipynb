{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DKGPR\n",
    "\n",
    "This notebook demonstrates how to use the DKGPR for Microscopy-Spectroscopy\n",
    "\n",
    "**Author:** Yongtao Liu \n",
    "\n",
    "**Date:** January 2026"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1120edf10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dkgp'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Import DKGP\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdkgp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dkgpr, dkgpc\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdkgp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01macquisition\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      4\u001b[39m     expected_improvement,\n\u001b[32m      5\u001b[39m     upper_confidence_bound,\n\u001b[32m      6\u001b[39m     probability_of_improvement)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'dkgp'"
     ]
    }
   ],
   "source": [
    "# Import DKGP\n",
    "from dkgp import dkgpr, dkgpc\n",
    "from dkgp.acquisition import (\n",
    "    expected_improvement,\n",
    "    upper_confidence_bound,\n",
    "    probability_of_improvement)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper function\n",
    "\n",
    "\"\"\"The loop area of the hysteresis curve is related to:\n",
    " --Strength of ferroelectric switching\n",
    " --Energy dissipation during polarization reversal\n",
    " --Quality of the ferroelectric material at that location\"\"\"\n",
    "\n",
    "def loop_area(raw_spec, cycle):\n",
    "    \"\"\"Calculate loop area from spectrum.\"\"\"\n",
    "    raw_spec_len = len(raw_spec)\n",
    "    cycle_len = int(raw_spec_len / cycle)\n",
    "    half_len = int(cycle_len / 2)\n",
    "    q_len = int(cycle_len / 4)\n",
    "    loop_top, loop_bottom = [], []\n",
    "    loop_top.append(raw_spec[q_len : q_len + half_len])\n",
    "    loop_top.append(raw_spec[q_len + 2*half_len : q_len + 3*half_len])\n",
    "    loop_top.append(raw_spec[q_len + 4*half_len : 2*q_len + 4*half_len])\n",
    "    loop_bottom.append(raw_spec[:q_len])\n",
    "    loop_bottom.append(raw_spec[q_len + half_len: q_len + 2*half_len])\n",
    "    loop_bottom.append(raw_spec[q_len + 3*half_len: q_len + 4*half_len])\n",
    "    loop_top = np.concatenate(loop_top)\n",
    "    loop_bottom = np.concatenate(loop_bottom)\n",
    "    return np.abs(np.sum(loop_top) - np.sum(loop_bottom))\n",
    "\n",
    "norm_ = lambda x: (x - x.min()) / np.ptp(x)\n",
    "\n",
    "def get_grid_coords (img, step=1):\n",
    "    \"\"\"\n",
    "    Generate coordinate grid for a single 2D image.\n",
    "    \n",
    "    Args:\n",
    "        img: 2D numpy array\n",
    "        step: distance between grid points\n",
    "    \n",
    "    Returns:\n",
    "        N x 2 array of (y, x) coordinates\n",
    "    \"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    coords = []\n",
    "    for i in range(0, h, step):\n",
    "        for j in range(0, w, step):\n",
    "            coords.append([i, j])\n",
    "    return np.array(coords)\n",
    "\n",
    "\n",
    "def get_subimages(img, coordinates, window_size):\n",
    "    \"\"\"\n",
    "    Extract subimages centered at given coordinates.\n",
    "    \n",
    "    Args:\n",
    "        img: 2D or 3D numpy array (h, w) or (h, w, c)\n",
    "        coordinates: N x 2 array of (y, x) coordinates\n",
    "        window_size: size of square window to extract\n",
    "    \n",
    "    Returns:\n",
    "        subimages: (N, window_size, window_size, channels) array\n",
    "        valid_coords: coordinates where extraction succeeded\n",
    "        valid_indices: indices of valid extractions\n",
    "    \"\"\"\n",
    "    if img.ndim == 2:\n",
    "        img = img[..., None]\n",
    "    \n",
    "    h, w, c = img.shape\n",
    "    half_w = window_size // 2\n",
    "    \n",
    "    subimages = []\n",
    "    valid_coords = []\n",
    "    valid_indices = []\n",
    "    \n",
    "    for idx, (y, x) in enumerate(coordinates):\n",
    "        # Check boundaries\n",
    "        if (y - half_w >= 0 and y + half_w <= h and\n",
    "            x - half_w >= 0 and x + half_w <= w):\n",
    "            \n",
    "            patch = img[y - half_w:y + half_w,\n",
    "                       x - half_w:x + half_w, :]\n",
    "            \n",
    "            if patch.shape[0] == window_size and patch.shape[1] == window_size:\n",
    "                subimages.append(patch)\n",
    "                valid_coords.append([y, x])\n",
    "                valid_indices.append(idx)\n",
    "    \n",
    "    return (np.array(subimages), \n",
    "            np.array(valid_coords), \n",
    "            np.array(valid_indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bepsdata = np.load(\"/Users/yla/Documents/BEPS_PTO_1d7um.npz\")\n",
    "amp_off_field = bepsdata['amp_off_field']\n",
    "pha_off_field = bepsdata['pha_off_field']\n",
    "v_step = bepsdata['v_step']\n",
    "\n",
    "pola_off_field = amp_off_field * np.cos(pha_off_field)*1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a region for exploration\n",
    "exp_data = pola_off_field\n",
    "img_data = amp_off_field\n",
    "struc_img = img_data.mean(2)\n",
    "\n",
    "# Visualize\n",
    "plot_pixx1, plot_pixy1 = 10, 30\n",
    "plot_pixx2, plot_pixy2 = 30, 10\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(9, 4))\n",
    "ax1.imshow(struc_img)\n",
    "ax1.scatter(plot_pixx1, plot_pixy1, marker='x', s=100, c='k')\n",
    "ax1.scatter(plot_pixx2, plot_pixy2, marker='x', s=100, c='r')\n",
    "ax1.set_title('Structure Image')\n",
    "ax1.axis(\"off\")\n",
    "\n",
    "ax2.plot(v_step, exp_data[plot_pixx1, plot_pixy1], c='k')\n",
    "ax2.plot(v_step, exp_data[plot_pixx2, plot_pixy2], c='r')\n",
    "ax2.set_xlabel('Voltage (V)')\n",
    "ax2.set_ylabel('Polarization (a.u.)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract image patches and spectra\n",
    "img = norm_(struc_img)\n",
    "spectra = norm_(exp_data)\n",
    "\n",
    "coordinates = get_grid_coords(img, step=1)\n",
    "window_size = 16\n",
    "features_all, coords, _ = get_subimages(img, coordinates, window_size)\n",
    "features_all = features_all[:,:,:,0]\n",
    "coords = np.array(coords, dtype=int)\n",
    "targets = spectra[coords[:, 0], coords[:, 1]]\n",
    "\n",
    "print('Coordinates shape:', coords.shape)\n",
    "print('Image patches shape:', features_all.shape)\n",
    "print('Spectra shape:', spectra.shape)\n",
    "print('Target spectra shape:', targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize example patch\n",
    "k_example = 100\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(9, 3), dpi=100)\n",
    "ax1.imshow(img, origin='lower')\n",
    "ax1.scatter(coords[k_example, 1], coords[k_example, 0], marker='x', s=50, c='k')\n",
    "ax1.axis(\"off\")\n",
    "ax1.set_title('Full Image')\n",
    "\n",
    "ax2.imshow(features_all[k_example], origin='lower')\n",
    "ax2.axis(\"off\")\n",
    "ax2.set_title('Image Patch')\n",
    "\n",
    "ax3.plot(v_step, spectra[coords[k_example, 0], coords[k_example, 1]])\n",
    "ax3.set_title('Spectrum')\n",
    "ax3.set_xlabel('Voltage (V)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize and compute loop areas\n",
    "features = norm_(features_all)\n",
    "targets = norm_(targets)\n",
    "\n",
    "loop_areas_all = []\n",
    "for i, t in enumerate(targets):\n",
    "    looparea = loop_area(t, 3)\n",
    "    loop_areas_all.append(np.array([looparea]))\n",
    "\n",
    "loop_areas_all = np.concatenate(loop_areas_all)\n",
    "\n",
    "# Visualize loop areas\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "a = ax1.scatter(coords[:, 1], coords[:, 0], c=loop_areas_all, cmap='viridis')\n",
    "plt.colorbar(a, ax=ax1)\n",
    "ax1.set_title('Loop Area')\n",
    "ax1.set_aspect('equal')\n",
    "\n",
    "ax2.imshow(struc_img, origin=\"lower\")\n",
    "ax2.set_title('Structure Image')\n",
    "ax2.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data arrays\n",
    "n, d1, d2 = features_all.shape\n",
    "X = features_all.reshape(n, d1*d2)  # Flattened patches for DKL\n",
    "y = norm_(loop_areas_all)  # Scalarized values\n",
    "\n",
    "print(f\"X_train shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"Coords shape: {coords.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select initial training points\n",
    "np.random.seed(5)\n",
    "start_size = 100\n",
    "train_indices = np.random.choice(np.arange(1, n), size=start_size, replace=False)\n",
    "print(\"Initial training indices (pool indices):\", train_indices)\n",
    "\n",
    "X_train = X[train_indices]\n",
    "y_train = y[train_indices]\n",
    "coord_train = coords[train_indices]\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"Coordinates shape: {coord_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Deep Kernel GP\n",
    "mll, gp_model, dkl_model, losses = fit_dkgp(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    feature_dim=4,           # Reduce 100D -> 16D\n",
    "    hidden_dims=[32, 16, 8],  # Neural network architecture\n",
    "    num_epochs=1000,          # Training iterations\n",
    "    lr_features=1e-4,         # Learning rate for neural network\n",
    "    lr_gp=1e-2,              # Learning rate for GP\n",
    "    verbose=True,\n",
    "    plot_loss=False         \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 4))\n",
    "\n",
    "plt.subplot()\n",
    "plt.plot(losses, linewidth=2, color='#2E86AB')\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Negative Log Likelihood', fontsize=12)\n",
    "plt.title('Training Loss', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final loss: {losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "mean_pred, std_pred = predict(dkl_model, X, return_std=True)\n",
    "\n",
    "print(f\"Predictions shape: {mean_pred.shape}\")\n",
    "print(f\"Uncertainty shape: {std_pred.shape}\")\n",
    "print(f\"Mean uncertainty: {std_pred.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize loop areas\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 4))\n",
    "a = ax1.scatter(coords[:, 1], coords[:, 0], c=y, cmap='viridis')\n",
    "plt.colorbar(a, ax=ax1)\n",
    "ax1.set_title('Ground Truth Loop Area')\n",
    "ax1.set_aspect('equal')\n",
    "\n",
    "b=ax2.scatter(coords[:, 1], coords[:, 0], c=mean_pred, cmap='viridis')\n",
    "ax2.set_title('Predicted Loop Area')\n",
    "plt.colorbar(b, ax=ax2)\n",
    "ax2.set_aspect('equal')\n",
    "\n",
    "c=ax3.scatter(coords[:, 1], coords[:, 0], c=std_pred, cmap='viridis')\n",
    "ax3.set_title('Uncertainty')\n",
    "plt.colorbar(c, ax=ax3)\n",
    "ax3.set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def branin_high_dim(x):\n",
    "    \"\"\"\n",
    "    Branin function (classic optimization benchmark) in high dimensions.\n",
    "    Only first 2 dimensions matter, rest are noise.\n",
    "    Global minimum ≈ 0.398 at (π, 2.275) and two other locations.\n",
    "    \"\"\"\n",
    "    x1 = x[0] * 15 - 5   # Scale to [-5, 10]\n",
    "    x2 = x[1] * 15        # Scale to [0, 15]\n",
    "    \n",
    "    a = 1\n",
    "    b = 5.1 / (4 * np.pi**2)\n",
    "    c = 5 / np.pi\n",
    "    r = 6\n",
    "    s = 10\n",
    "    t = 1 / (8 * np.pi)\n",
    "    \n",
    "    term1 = a * (x2 - b * x1**2 + c * x1 - r)**2\n",
    "    term2 = s * (1 - t) * np.cos(x1)\n",
    "    term3 = s\n",
    "    \n",
    "    # Add small noise from other dimensions\n",
    "    if len(x) > 2:\n",
    "        noise = 0.05 * np.sum(x[2:]**2)\n",
    "    else:\n",
    "        noise = 0\n",
    "    \n",
    "    return term1 + term2 + term3 + noise\n",
    "\n",
    "print(f\"True global minimum: ≈ 0.398\")\n",
    "print(f\"Test evaluation: {branin_high_dim(np.array([0.5424, 0.1517] + [0]*18)):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize with Random Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem setup\n",
    "input_dim = 20\n",
    "n_initial = 10\n",
    "n_iterations = 15\n",
    "\n",
    "# Generate candidate pool\n",
    "n_candidates = 2000\n",
    "candidates = np.random.uniform(0, 1, size=(n_candidates, input_dim))\n",
    "\n",
    "# Initial random samples\n",
    "initial_idx = np.random.choice(n_candidates, n_initial, replace=False)\n",
    "X_observed = candidates[initial_idx]\n",
    "y_observed = np.array([branin_high_dim(x) for x in X_observed])\n",
    "\n",
    "print(f\"Initial samples: {n_initial}\")\n",
    "print(f\"Initial best: {y_observed.min():.4f}\")\n",
    "print(f\"Candidate pool: {n_candidates} points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Bayesian Optimization Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track progress\n",
    "best_values = [y_observed.min()]\n",
    "all_values = list(y_observed)\n",
    "ei_values_history = []\n",
    "\n",
    "print(\"Starting Bayesian Optimization...\\n\")\n",
    "print(f\"{'Iter':<6} {'Next f(x)':<12} {'Best f(x)':<12} {'Max EI':<12}\")\n",
    "print(\"=\"*48)\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    # Train model on current observations\n",
    "    _, _, model, _ = fit_dkgp(\n",
    "        X_observed,\n",
    "        y_observed,\n",
    "        feature_dim=16,\n",
    "        num_epochs=500,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Get current best\n",
    "    best_f = y_observed.min()\n",
    "    \n",
    "    # Remove already evaluated candidates\n",
    "    mask = np.ones(len(candidates), dtype=bool)\n",
    "    for x in X_observed:\n",
    "        mask &= ~np.all(np.isclose(candidates, x), axis=1)\n",
    "    available = candidates[mask]\n",
    "    \n",
    "    # Compute Expected Improvement\n",
    "    ei = expected_improvement(\n",
    "        model,\n",
    "        available,\n",
    "        best_f=best_f,\n",
    "        xi=0.01,\n",
    "        maximize=False  # Minimize Branin\n",
    "    )\n",
    "    \n",
    "    # Select next point\n",
    "    next_idx = np.argmax(ei)\n",
    "    next_point = available[next_idx]\n",
    "    next_value = branin_high_dim(next_point)\n",
    "    \n",
    "    # Update observations\n",
    "    X_observed = np.vstack([X_observed, next_point])\n",
    "    y_observed = np.append(y_observed, next_value)\n",
    "    \n",
    "    # Track progress\n",
    "    best_values.append(y_observed.min())\n",
    "    all_values.append(next_value)\n",
    "    ei_values_history.append(ei.max())\n",
    "    \n",
    "    print(f\"{iteration+1:<6} {next_value:<12.4f} {y_observed.min():<12.4f} {ei.max():<12.6f}\")\n",
    "\n",
    "print(\"=\"*48)\n",
    "print(f\"\\nOptimization complete!\")\n",
    "print(f\"Final best value: {y_observed.min():.4f}\")\n",
    "print(f\"True global minimum: 0.398\")\n",
    "print(f\"Gap: {y_observed.min() - 0.398:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Optimization Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Best value over iterations\n",
    "axes[0, 0].plot(best_values, 'o-', linewidth=2, markersize=8, color='#2E86AB')\n",
    "axes[0, 0].axhline(y=0.398, color='r', linestyle='--', linewidth=2, label='Global minimum')\n",
    "axes[0, 0].set_xlabel('Iteration', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Best f(x) Found', fontsize=12)\n",
    "axes[0, 0].set_title('Optimization Progress', fontsize=13, fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. All evaluations\n",
    "axes[0, 1].plot(all_values, 'o', alpha=0.6, markersize=6, color='#A23B72')\n",
    "axes[0, 1].axhline(y=0.398, color='r', linestyle='--', linewidth=2, label='Global minimum')\n",
    "axes[0, 1].axvline(x=n_initial-0.5, color='k', linestyle=':', linewidth=2, label='Initial samples')\n",
    "axes[0, 1].set_xlabel('Evaluation', fontsize=12)\n",
    "axes[0, 1].set_ylabel('f(x)', fontsize=12)\n",
    "axes[0, 1].set_title('All Evaluations', fontsize=13, fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Expected Improvement over iterations\n",
    "axes[1, 0].plot(ei_values_history, 's-', linewidth=2, markersize=7, color='#F18F01')\n",
    "axes[1, 0].set_xlabel('Iteration', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Max Expected Improvement', fontsize=12)\n",
    "axes[1, 0].set_title('Acquisition Function Values', fontsize=13, fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Cumulative improvement\n",
    "improvements = np.maximum.accumulate(-np.array(best_values))  # Negative for minimization\n",
    "axes[1, 1].plot(improvements, 'o-', linewidth=2, markersize=8, color='#C73E1D')\n",
    "axes[1, 1].set_xlabel('Iteration', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Cumulative Improvement', fontsize=12)\n",
    "axes[1, 1].set_title('Total Improvement Over Initial Best', fontsize=13, fontweight='bold')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Acquisition Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model\n",
    "_, _, final_model, _ = fit_dkgp(\n",
    "    X_observed, y_observed,\n",
    "    feature_dim=16,\n",
    "    num_epochs=500,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Sample some test candidates\n",
    "test_candidates = np.random.uniform(0, 1, (100, input_dim))\n",
    "best_f = y_observed.min()\n",
    "\n",
    "# Compute different acquisition functions\n",
    "ei = expected_improvement(final_model, test_candidates, best_f, maximize=False)\n",
    "ucb = upper_confidence_bound(final_model, test_candidates, beta=2.0, maximize=False)\n",
    "pi = probability_of_improvement(final_model, test_candidates, best_f, maximize=False)\n",
    "\n",
    "# Normalize for comparison\n",
    "ei_norm = (ei - ei.min()) / (ei.max() - ei.min() + 1e-8)\n",
    "ucb_norm = (ucb - ucb.min()) / (ucb.max() - ucb.min() + 1e-8)\n",
    "pi_norm = (pi - pi.min()) / (pi.max() - pi.min() + 1e-8)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "x = np.arange(len(test_candidates))\n",
    "width = 0.25\n",
    "\n",
    "plt.bar(x - width, ei_norm, width, label='EI', alpha=0.8)\n",
    "plt.bar(x, ucb_norm, width, label='UCB', alpha=0.8)\n",
    "plt.bar(x + width, pi_norm, width, label='PI', alpha=0.8)\n",
    "\n",
    "plt.xlabel('Candidate Index', fontsize=12)\n",
    "plt.ylabel('Normalized Acquisition Value', fontsize=12)\n",
    "plt.title('Comparison of Acquisition Functions', fontsize=13, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show top candidates for each\n",
    "print(\"\\nTop 3 candidates by acquisition function:\")\n",
    "print(f\"  EI:  indices {np.argsort(ei)[-3:][::-1]}\")\n",
    "print(f\"  UCB: indices {np.argsort(ucb)[:3]}\")\n",
    "print(f\"  PI:  indices {np.argsort(pi)[-3:][::-1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DKGP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
